# Statistical Learning and Data Mining (QBUS6810)
**Marcel Scharth, The University of Sydney**

This is a repository for the Jupyter Notebooks and code used in Statistical Learning Data Mining, postgraduate unit at the University of Sydney Business School. I additionally provide the lectures in case you need them for future reference. 

This version: Semester 2, 2017.

## Python Tutorials (under construction)

[Tutorial 1: Working with Data in Python]()
<br/>[Tutorial 2: K-Nearest Neighbours Regression]()
<br/>[Tutorial 3: Regression Modelling]()
<br/>[Tutorial 4: Cross Validation]()
<br/>[Tutorial 5: The Bootstrap]()
<br/>[Tutorial 6: Linear Model Selection and Regularisation]()
<br/>[Tutorial 7: Naive Bayes and Sentiment Analysis]()
<br/>[Tutorial 8: Logistic Regression and Gaussian Discriminant Analysis]()
<br/>[Tutorial 9: Regression Splines]()
<br/>[Tutorial 10: Regression Trees]()
<br/>[Tutorial 11: Model Stacking]()
<br/>[Tutorial 12: Credit Risk Modelling]()

## Lectures (under construction)

[Module 1: Introduction to Statistical Learning]()
<br/>[Module 2: Linear Regression and Statistical Thinking]()
<br/>[Module 3: K-Nearest Neighbours Regression]()
<br/>[Module 4: Regression Modelling]()
<br/>[Module 5: Model Selection]()
<br/>[Module 6: The Bootstrap]()
<br/>[Module 7: Estimation Methods (reference module)]()
<br/>[Module 8: Linear model Selection and Regularisation I]()
<br/>[Module 9: Linear model Selection and Regularisation II]()
<br/>[Module 10: Classification I]()
<br/>[Module 11: Classification II]()
<br/>[Module 12: Nonlinear Modelling]()
<br/>[Module 13: Tree-based Methods]()
<br/>[Module 14: Model Stacking]()
<br/>[Module 15: Boosting]()

Acknowledgement: these lectures use figures from Introduction to Statistical Learning and Elements of Statistical Learning (see below).

## References

Textbook:

[An Introduction to Statistical Learning](https://www.amazon.com/Introduction-Statistical-Learning-Applications-Statistics/dp/1461471370/) by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani.

The lectures and tutorials also draw on material from: 

[The Elements of Statistical Learning](https://www.amazon.com/Elements-Statistical-Learning-Prediction-Statistics/dp/0387848576/) by Trevor Hastie and Robert Tibshirani.

[Statistical Methods in Customer Relationship Management](https://www.amazon.com/Statistical-Methods-Customer-Relationship-Management/dp/1119993202/) by V. Kumar and J. Andrew Petersen.

[Machine Learning: A Probabilistic Perspective](https://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020/) by Kevin P. Murphy. 

[Mathematical Statistics with Resampling and R](https://www.amazon.com/Mathematical-Statistics-Resampling-Laura-Chihara/dp/1118029852/) by Laura M. Chihara and Tim C. Hesterberg.

## Other resources

Students are highly encouraged to encourage to consider the following additonal resouces.

[A Mind for Numbers: How to Excel at Math and Science](https://www.amazon.com/Mind-Numbers-Science-Flunked-Algebra/) by Barbara Oakley.

[Dataquest](https://www.dataquest.io/) (Python online course).

[DataCamp](https://www.datacamp.com/) (Python online course).

[Learning Data Science (Kaggle Wiki)](https://www.kaggle.com/wiki/Home)

[Kaggle Kernels](https://www.kaggle.com/kernels)
